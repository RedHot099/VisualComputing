{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularyzacja przez mnożniki Lagrange'a. Algorytm SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Zadanie 1 (2pkt):\n",
    "\n",
    "Rozwiń algorytm regresji logistycznej z lab. 1, wprowadzając do niego człon regularyzacyjny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Methods definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread\n",
    "import cv2 as cv\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "required = {\"scikit-image\"}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call(\n",
    "        [python, \"-m\", \"pip\", \"install\", *missing], stdout=subprocess.DEVNULL\n",
    "    )\n",
    "\n",
    "\n",
    "def load_train_data(input_dir, newSize=(64, 64)):\n",
    "    image_dir = Path(input_dir)\n",
    "    categories_name = []\n",
    "    for file in os.listdir(image_dir):\n",
    "        d = os.path.join(image_dir, file)\n",
    "        if os.path.isdir(d):\n",
    "            categories_name.append(file)\n",
    "\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "\n",
    "    train_img = []\n",
    "    categories_count = []\n",
    "    labels = []\n",
    "    for _, direc in enumerate(folders):\n",
    "        count = 0\n",
    "        for obj in direc.iterdir():\n",
    "            if (\n",
    "                os.path.isfile(obj)\n",
    "                and os.path.basename(os.path.normpath(obj)) != \"desktop.ini\"\n",
    "            ):\n",
    "                labels.append(os.path.basename(os.path.normpath(direc)))\n",
    "                count += 1\n",
    "                img = imread(obj)  # zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "                img = cv.resize(\n",
    "                    img, newSize, interpolation=cv.INTER_AREA\n",
    "                )  # zwraca ndarray\n",
    "                if img[0][0].size==3:\n",
    "                    img =  np.dstack((img,np.ones((64,64,1))))\n",
    "                img = img / 255  # normalizacja\n",
    "                train_img.append(img)\n",
    "        categories_count.append(count)\n",
    "    X = {}\n",
    "    # return train_img\n",
    "    X[\"values\"] = np.array(train_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"] = labels\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_data(input_dir, newSize=(64, 64)):\n",
    "    image_path = Path(input_dir)\n",
    "    labels_path = image_path.parents[0] / \"test_labels.json\"\n",
    "\n",
    "    # with labels_path.open(\"r\", encoding =\"utf-8\") as f:\n",
    "    jsonString = labels_path.read_text()\n",
    "    objects = json.loads(jsonString)\n",
    "\n",
    "    categories_name = []\n",
    "    categories_count = []\n",
    "    count = 0\n",
    "    c = objects[0][\"value\"]\n",
    "    for e in objects:\n",
    "        if e[\"value\"] != c:\n",
    "            # print(count)\n",
    "            # print(c)\n",
    "            categories_count.append(count)\n",
    "            c = e[\"value\"]\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "        if not e[\"value\"] in categories_name:\n",
    "            categories_name.append(e[\"value\"])\n",
    "    categories_count.append(count)\n",
    "\n",
    "    test_img = []\n",
    "    labels = []\n",
    "\n",
    "    for e in objects:\n",
    "        p = image_path / e[\"filename\"]\n",
    "        img = imread(p)  # zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "        img = cv.resize(img, newSize, interpolation=cv.INTER_AREA)  # zwraca ndarray\n",
    "        img = img / 255  # normalizacja\n",
    "        test_img.append(img)\n",
    "        labels.append(e[\"value\"])\n",
    "\n",
    "    X = {}\n",
    "    X[\"values\"] = np.array(test_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"] = labels\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "data_train = load_train_data(\"./train_test_sw/train_sw\", newSize=(64, 64))\n",
    "X_train = data_train[\"values\"]\n",
    "y_train = data_train[\"labels\"]\n",
    "\n",
    "data_test = load_test_data(\"./train_test_sw/test_sw\", newSize=(64, 64))\n",
    "X_test = data_test[\"values\"]\n",
    "y_test = data_test[\"labels\"]\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y_train_enc = class_le.fit_transform(y_train)\n",
    "y_test_enc = class_le.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogReg class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, data_shape, classes_no) -> None:\n",
    "        self.w = np.zeros(shape=(classes_no, data_shape[0], 1))\n",
    "        self.b = np.zeros(shape=(classes_no, 1))\n",
    "        print(f\"self.w.shape = {self.w.shape}\\nself.b.shape = {self.b.shape}\")\n",
    "\n",
    "    def sigmoid(self, z) -> float:\n",
    "        return 1 / (1 + np.exp(-z)) - 0.0000001\n",
    "\n",
    "    def propagate(self, w, b, X, Y, regularization, lambda_param) -> tuple:\n",
    "        data_len = X.shape[1]\n",
    "\n",
    "        A = self.sigmoid((np.dot(w.T, X) + b))\n",
    "\n",
    "        # ==========================\n",
    "        # Regularization part\n",
    "        reg_val = lambda_param * np.sum(w.T) if regularization else 0\n",
    "        cost = (\n",
    "            np.sum(((-np.log(A)) * Y + (-np.log(1 - A)) * (1 - Y))) - reg_val\n",
    "        ) / data_len\n",
    "        # ==========================\n",
    "\n",
    "        cost = np.squeeze(cost)\n",
    "\n",
    "        dw = (np.dot(X, (A - Y).T)) / data_len\n",
    "        db = (np.sum(A - Y)) / data_len\n",
    "\n",
    "        grads = {\"dw\": dw, \"db\": db}\n",
    "        return grads, cost\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        Y,\n",
    "        num_iterations,\n",
    "        lr,\n",
    "        verbose=False,\n",
    "        regularization=None,\n",
    "        lambda_param=0.1,\n",
    "    ) -> dict:\n",
    "        error_vals = [[] for i in range(self.w.shape[0])]\n",
    "        for i in range(num_iterations):\n",
    "            if (i + 1) % 100 == 1 or i == num_iterations - 1:\n",
    "                print(\"Iteration:\", i)\n",
    "            for ent_class in range(self.w.shape[0]):\n",
    "\n",
    "                grads, cost = self.propagate(\n",
    "                    self.w[ent_class],\n",
    "                    self.b[ent_class],\n",
    "                    X,\n",
    "                    Y[ent_class],\n",
    "                    regularization,\n",
    "                    lambda_param,\n",
    "                )\n",
    "                # print(f\"\\t{i}before w update\")\n",
    "                self.w[ent_class] -= lr * grads[\"dw\"]\n",
    "                # print(\"\\tbefore b update\")\n",
    "                self.b[ent_class] -= lr * grads[\"db\"]\n",
    "                if (i + 1) % 100 == 1 or i == num_iterations - 1:\n",
    "                    error_vals[ent_class].append(cost)\n",
    "                    if verbose:\n",
    "                        print(f\"\\tClass: {ent_class} → error: {cost}\")\n",
    "        return {\n",
    "            \"parameters\": {\"w\": self.w, \"b\": self.b},\n",
    "            \"gradients\": grads,\n",
    "            \"error_values\": error_vals,\n",
    "        }\n",
    "\n",
    "    def predict(self, X) -> list:\n",
    "        A = np.array(\n",
    "            [\n",
    "                self.sigmoid(np.dot(current_w.reshape(X.shape[0], -1).T, X) + current_b)\n",
    "                for current_w, current_b in zip(self.w, self.b)\n",
    "            ]\n",
    "        )\n",
    "        Y_pred = [(class_preds > 0.5) * 1.0 for class_preds in A]  # A * 5.0\n",
    "        return Y_pred\n",
    "\n",
    "    def validate(self, test_data, true_labels) -> str:\n",
    "        preds = self.predict(test_data)\n",
    "        return f\"Accuracy for the given data → {100 - np.mean(np.abs(preds - true_labels))*100}\"\n",
    "\n",
    "\n",
    "def prepare_data(x_data, y_data) -> tuple:\n",
    "    x = x_data.reshape(x_data.shape[0], -1).T\n",
    "    y = np.array([[int(x == i) for i in y_data] for x in range(len(set(y_data)))])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.w.shape = (5, 16384, 1)\n",
      "self.b.shape = (5, 1)\n",
      "Iteration: 0\n",
      "\tClass: 0 → error: 0.6931470596252036\n",
      "\tClass: 1 → error: 0.6931470607936555\n",
      "\tClass: 2 → error: 0.6931470607936555\n",
      "\tClass: 3 → error: 0.6931470607936555\n",
      "\tClass: 4 → error: 0.6931470607936555\n",
      "Iteration: 100\n",
      "\tClass: 0 → error: 0.4267814228420924\n",
      "\tClass: 1 → error: 0.49106950859658366\n",
      "\tClass: 2 → error: 0.48079657435762524\n",
      "\tClass: 3 → error: 0.483711936075606\n",
      "\tClass: 4 → error: 0.4800875219526501\n",
      "Iteration: 200\n",
      "\tClass: 0 → error: 0.3907069724129813\n",
      "\tClass: 1 → error: 0.48388959897515377\n",
      "\tClass: 2 → error: 0.4644157832460014\n",
      "\tClass: 3 → error: 0.4716988962252928\n",
      "\tClass: 4 → error: 0.46848768835863797\n",
      "Iteration: 300\n",
      "\tClass: 0 → error: 0.3684083064604981\n",
      "\tClass: 1 → error: 0.478110817242968\n",
      "\tClass: 2 → error: 0.4504614181247573\n",
      "\tClass: 3 → error: 0.4623617531091419\n",
      "\tClass: 4 → error: 0.46119779803927824\n",
      "Iteration: 400\n",
      "\tClass: 0 → error: 0.3524730223063941\n",
      "\tClass: 1 → error: 0.4730996505359099\n",
      "\tClass: 2 → error: 0.4381849580583522\n",
      "\tClass: 3 → error: 0.4546017818252095\n",
      "\tClass: 4 → error: 0.45613360147541876\n",
      "Iteration: 500\n",
      "\tClass: 0 → error: 0.33988678051216903\n",
      "\tClass: 1 → error: 0.46855063676153835\n",
      "\tClass: 2 → error: 0.42715391953100995\n",
      "\tClass: 3 → error: 0.4478582276563406\n",
      "\tClass: 4 → error: 0.45231355142109175\n",
      "Iteration: 600\n",
      "\tClass: 0 → error: 0.3292757813206268\n",
      "\tClass: 1 → error: 0.4643066609162233\n",
      "\tClass: 2 → error: 0.417102411139581\n",
      "\tClass: 3 → error: 0.44182370396829956\n",
      "\tClass: 4 → error: 0.4492349509190939\n",
      "Iteration: 700\n",
      "\tClass: 0 → error: 0.3199514221506185\n",
      "\tClass: 1 → error: 0.46028278896969294\n",
      "\tClass: 2 → error: 0.4078556618914755\n",
      "\tClass: 3 → error: 0.43631815234201743\n",
      "\tClass: 4 → error: 0.4466222416191652\n",
      "Iteration: 800\n",
      "\tClass: 0 → error: 0.31153951352495907\n",
      "\tClass: 1 → error: 0.4564308041792506\n",
      "\tClass: 2 → error: 0.39929081243385267\n",
      "\tClass: 3 → error: 0.4312292572936618\n",
      "\tClass: 4 → error: 0.4443161519675779\n",
      "Iteration: 900\n",
      "\tClass: 0 → error: 0.30382161130631863\n",
      "\tClass: 1 → error: 0.4527218505132725\n",
      "\tClass: 2 → error: 0.39131629426725456\n",
      "\tClass: 3 → error: 0.42648267025747094\n",
      "\tClass: 4 → error: 0.44222068723959873\n",
      "Iteration: 1000\n",
      "\tClass: 0 → error: 0.29666144291755636\n",
      "\tClass: 1 → error: 0.4491376029510933\n",
      "\tClass: 2 → error: 0.38386062975406793\n",
      "\tClass: 3 → error: 0.42202637452736\n",
      "\tClass: 4 → error: 0.4402759854731208\n",
      "Iteration: 1100\n",
      "\tClass: 0 → error: 0.2899684981849444\n",
      "\tClass: 1 → error: 0.44566563378843677\n",
      "\tClass: 2 → error: 0.37686605864394945\n",
      "\tClass: 3 → error: 0.4178221100194103\n",
      "\tClass: 4 → error: 0.4384436261307232\n",
      "Iteration: 1200\n",
      "\tClass: 0 → error: 0.2836790248824659\n",
      "\tClass: 1 → error: 0.4422969190267639\n",
      "\tClass: 2 → error: 0.37028470624181264\n",
      "\tClass: 3 → error: 0.4138404825233368\n",
      "\tClass: 4 → error: 0.4366983132817158\n",
      "Iteration: 1300\n",
      "\tClass: 0 → error: 0.2777456544065655\n",
      "\tClass: 1 → error: 0.4390244682194112\n",
      "\tClass: 2 → error: 0.3640761436154256\n",
      "\tClass: 3 → error: 0.41005807069180344\n",
      "\tClass: 4 → error: 0.4350229917736028\n",
      "Iteration: 1400\n",
      "\tClass: 0 → error: 0.2721315133776044\n",
      "\tClass: 1 → error: 0.43584255772829483\n",
      "\tClass: 2 → error: 0.3582057469610267\n",
      "\tClass: 3 → error: 0.40645565299815267\n",
      "\tClass: 4 → error: 0.4334058917955604\n",
      "Iteration: 1500\n",
      "\tClass: 0 → error: 0.2668067610008\n",
      "\tClass: 1 → error: 0.43274629392713065\n",
      "\tClass: 2 → error: 0.35264353973928336\n",
      "\tClass: 3 → error: 0.40301708184880836\n",
      "\tClass: 4 → error: 0.43183869542066294\n",
      "Iteration: 1600\n",
      "\tClass: 0 → error: 0.2617464832633894\n",
      "\tClass: 1 → error: 0.4297313593714053\n",
      "\tClass: 2 → error: 0.3473633417294856\n",
      "\tClass: 3 → error: 0.3997285424907767\n",
      "\tClass: 4 → error: 0.4303153754551368\n",
      "Iteration: 1700\n",
      "\tClass: 0 → error: 0.25692936899321417\n",
      "\tClass: 1 → error: 0.4267938615932156\n",
      "\tClass: 2 → error: 0.34234212280423126\n",
      "\tClass: 3 → error: 0.3965780472603917\n",
      "\tClass: 4 → error: 0.4288314472469605\n",
      "Iteration: 1800\n",
      "\tClass: 0 → error: 0.2523368488417465\n",
      "\tClass: 1 → error: 0.4239302400464309\n",
      "\tClass: 2 → error: 0.33755949923924505\n",
      "\tClass: 3 → error: 0.39355507795808586\n",
      "\tClass: 4 → error: 0.42738347950037603\n",
      "Iteration: 1900\n",
      "\tClass: 0 → error: 0.2479525154929903\n",
      "\tClass: 1 → error: 0.42113720635557633\n",
      "\tClass: 2 → error: 0.3329973329772806\n",
      "\tClass: 3 → error: 0.39065032426223145\n",
      "\tClass: 4 → error: 0.42596877042274905\n",
      "Iteration: 1999\n",
      "\tClass: 0 → error: 0.24380271344694177\n",
      "\tClass: 1 → error: 0.41843863416799215\n",
      "\tClass: 2 → error: 0.32868202489450415\n",
      "\tClass: 3 → error: 0.3878829157266927\n",
      "\tClass: 4 → error: 0.4245988198214675\n"
     ]
    }
   ],
   "source": [
    "X_train_flat, y_train_enc_multi = prepare_data(X_train, y_train_enc)\n",
    "\n",
    "# Logistic Regression training\n",
    "log_reg = LogisticRegression(X_train_flat.shape, classes_no=5)\n",
    "training_result = log_reg.fit(\n",
    "    X_train_flat,\n",
    "    y_train_enc_multi,\n",
    "    num_iterations=2000,\n",
    "    lr=0.0029,\n",
    "    verbose=True,\n",
    "    regularization=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the given data → 77.82239382239382%\n",
      "Precision for the given data → 0.7782239382239382\n",
      "Recall for the given data → 0.9640329060646643\n",
      "F1 score for the given data → 0.8612203042215006\n"
     ]
    }
   ],
   "source": [
    "X_test_flat, y_test_enc_multi = prepare_data(X_test, y_test_enc)\n",
    "\n",
    "preds = log_reg.predict(X_test_flat)\n",
    "size = np.size(preds - y_test_enc_multi)\n",
    "fp = np.sum(np.abs(preds - y_test_enc_multi))\n",
    "tp = size - fp\n",
    "fn = np.count_nonzero((preds - y_test_enc_multi) > 0)\n",
    "\n",
    "print(\n",
    "    f\"Accuracy for the given data → {100 - np.mean(np.abs(preds - y_test_enc_multi))*100}%\"\n",
    ")\n",
    "print(f\"Precision for the given data → { tp/(tp+fp) }\")\n",
    "print(f\"Recall for the given data → { tp/(tp+fn) }\")\n",
    "print(f\"F1 score for the given data → { 2*tp / (2*tp + fp + fn) }\")\n",
    "\n",
    "\n",
    "# print(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 2 (4pkt)\n",
    "\n",
    "Zaimplementuj algorytm SVM z miękkim marginesem (regularyzacją)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, x_train,y_train, classes_no,lambda_param=0.001) -> None:\n",
    "        self.x_train = np.array([x.flatten() for x in x_train])\n",
    "        self.y_train = y_train\n",
    "        self.lambda_param = lambda_param\n",
    "        self.w = np.zeros(shape=(self.x_train.shape[1],classes_no))\n",
    "        self.b = np.zeros(shape=(1,classes_no))\n",
    "        print(f\"self.w.shape = {self.w.shape}\\nself.b.shape = {self.b.shape}\")\n",
    "\n",
    "    def cost(self) -> tuple:\n",
    "        delta = 0.5\n",
    "        scores = np.dot(self.x_train,self.w) \n",
    "        correct_class_score = scores[np.arange(self.x_train.shape[0]), self.y_train]\n",
    "        margins = np.maximum(0, scores - correct_class_score[:,np.newaxis] + delta)\n",
    "        margins[np.arange(self.x_train.shape[0]), self.y_train] = 0\n",
    "        loss = np.sum(margins)/ self.x_train.shape[0]\n",
    "        loss +=   0.5*self.lambda_param* np.sum(self.w * self.w)\n",
    "        return loss, margins\n",
    "\n",
    "    def propagate(self) -> tuple:\n",
    "        loss,margins = self.cost()\n",
    "        error = np.zeros(margins.shape)\n",
    "        error[margins > 0] = 1 \n",
    "        count = np.sum(error,axis=1)\n",
    "        error[np.arange(self.x_train.shape[0]),self.y_train] = -count\n",
    "\n",
    "        dw = self.x_train.T.dot(error)/self.x_train.shape[0]\n",
    "\n",
    "        # Regularize\n",
    "        dw += 2*self.lambda_param*self.w\n",
    "        db = np.sum(error, axis=0) / self.x_train.shape[0]\n",
    "        db.reshape(1, 5)\n",
    "\n",
    "        grads = {\"dw\": dw, \"db\": db}\n",
    "        return grads, loss\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        num_iterations,\n",
    "        lr,\n",
    "        verbose=False,\n",
    "    ) -> dict:\n",
    "        error_vals = [[] for i in range(self.w.shape[0])]\n",
    "        for i in range(num_iterations):\n",
    "            if (i + 1) % 100 == 1 or i == num_iterations - 1:\n",
    "                print(\"Iteration:\", i)\n",
    "            for ent_class in range(self.w.shape[1]):\n",
    "\n",
    "                grads, cost = self.propagate()\n",
    "                # print(f\"\\t{i}before w update\")\n",
    "                self.w -= lr * grads[\"dw\"]\n",
    "                # print(\"\\tbefore b update\")\n",
    "                self.b -= lr * grads[\"db\"]\n",
    "                if (i + 1) % 100 == 1 or i == num_iterations - 1:\n",
    "                    error_vals[ent_class].append(cost)\n",
    "                    if verbose:\n",
    "                        print(f\"\\tClass: {ent_class} → error: {cost}\")\n",
    "        return {\n",
    "            \"parameters\": {\"w\": self.w, \"b\": self.b},\n",
    "            \"gradients\": grads,\n",
    "            \"error_values\": error_vals,\n",
    "        }\n",
    "\n",
    "    def predict(self,  X):\n",
    "        x_test_flat = np.array([x.flatten() for x in X])\n",
    "        result = np.dot(x_test_flat, self.w) + self.b\n",
    "        predictions = []\n",
    "        for row in result:\n",
    "            predictions.append(np.argmax(row))\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def validate(self, test_data, true_labels) -> str:\n",
    "        preds = self.predict(test_data)\n",
    "        return f\"Accuracy for the given data → {100 - np.mean(np.abs(preds - true_labels))*100}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.w.shape = (16384, 5)\n",
      "self.b.shape = (1, 5)\n",
      "Iteration: 0\n",
      "\tClass: 0 → error: 2.0\n",
      "\tClass: 1 → error: 1.9194132288668377\n",
      "\tClass: 2 → error: 1.890978847175176\n",
      "\tClass: 3 → error: 1.9097942714135943\n",
      "\tClass: 4 → error: 1.8959980659711146\n",
      "Iteration: 100\n",
      "\tClass: 0 → error: 1.6623180092919159\n",
      "\tClass: 1 → error: 1.6612885568350653\n",
      "\tClass: 2 → error: 1.6631550314370354\n",
      "\tClass: 3 → error: 1.6655844117895917\n",
      "\tClass: 4 → error: 1.664943893449542\n",
      "Iteration: 200\n",
      "\tClass: 0 → error: 1.5175044057731109\n",
      "\tClass: 1 → error: 1.5194915214217835\n",
      "\tClass: 2 → error: 1.5166437767764755\n",
      "\tClass: 3 → error: 1.5187938918703565\n",
      "\tClass: 4 → error: 1.5162035545871062\n",
      "Iteration: 300\n",
      "\tClass: 0 → error: 1.3974782174060494\n",
      "\tClass: 1 → error: 1.4008407822994857\n",
      "\tClass: 2 → error: 1.397069045643525\n",
      "\tClass: 3 → error: 1.4008128973066196\n",
      "\tClass: 4 → error: 1.3966637394058599\n",
      "Iteration: 400\n",
      "\tClass: 0 → error: 1.295251826735855\n",
      "\tClass: 1 → error: 1.2998978198878313\n",
      "\tClass: 2 → error: 1.294737712005439\n",
      "\tClass: 3 → error: 1.2994985230881682\n",
      "\tClass: 4 → error: 1.2944884076045935\n",
      "Iteration: 500\n",
      "\tClass: 0 → error: 1.205805273790647\n",
      "\tClass: 1 → error: 1.2111693146726135\n",
      "\tClass: 2 → error: 1.2055282595382515\n",
      "\tClass: 3 → error: 1.211279136116314\n",
      "\tClass: 4 → error: 1.2050676109369316\n",
      "Iteration: 600\n",
      "\tClass: 0 → error: 1.1255707216148378\n",
      "\tClass: 1 → error: 1.1305662232231748\n",
      "\tClass: 2 → error: 1.1254187926412005\n",
      "\tClass: 3 → error: 1.130169512374924\n",
      "\tClass: 4 → error: 1.125025077129275\n",
      "Iteration: 700\n",
      "\tClass: 0 → error: 1.0521249851785819\n",
      "\tClass: 1 → error: 1.0567362769345157\n",
      "\tClass: 2 → error: 1.0517461184998143\n",
      "\tClass: 3 → error: 1.0562368040467096\n",
      "\tClass: 4 → error: 1.0514238010966892\n",
      "Iteration: 800\n",
      "\tClass: 0 → error: 0.9870133154631392\n",
      "\tClass: 1 → error: 0.9932742574090139\n",
      "\tClass: 2 → error: 0.9864837770179881\n",
      "\tClass: 3 → error: 0.991722604140123\n",
      "\tClass: 4 → error: 0.9861048400531663\n",
      "Iteration: 900\n",
      "\tClass: 0 → error: 0.9257428839210816\n",
      "\tClass: 1 → error: 0.9299311846011098\n",
      "\tClass: 2 → error: 0.92532482487725\n",
      "\tClass: 3 → error: 0.9296993961293695\n",
      "\tClass: 4 → error: 0.9252039920281326\n",
      "Iteration: 1000\n",
      "\tClass: 0 → error: 0.8730404870001712\n",
      "\tClass: 1 → error: 0.8772584160036682\n",
      "\tClass: 2 → error: 0.8726128769998658\n",
      "\tClass: 3 → error: 0.8768154836156917\n",
      "\tClass: 4 → error: 0.8726270811331104\n",
      "Iteration: 1100\n",
      "\tClass: 0 → error: 0.8252066791926513\n",
      "\tClass: 1 → error: 0.8284270345934859\n",
      "\tClass: 2 → error: 0.824968678080639\n",
      "\tClass: 3 → error: 0.8282350057032537\n",
      "\tClass: 4 → error: 0.8248972957946564\n",
      "Iteration: 1200\n",
      "\tClass: 0 → error: 0.7743601033646522\n",
      "\tClass: 1 → error: 0.7801077282354728\n",
      "\tClass: 2 → error: 0.7746162736724111\n",
      "\tClass: 3 → error: 0.7799217336741706\n",
      "\tClass: 4 → error: 0.7740714370961178\n",
      "Iteration: 1300\n",
      "\tClass: 0 → error: 0.7656887800129791\n",
      "\tClass: 1 → error: 0.7665748730846046\n",
      "\tClass: 2 → error: 0.7659224899928107\n",
      "\tClass: 3 → error: 0.7668287282212616\n",
      "\tClass: 4 → error: 0.7660774361191173\n",
      "Iteration: 1400\n",
      "\tClass: 0 → error: 0.7426500582688108\n",
      "\tClass: 1 → error: 0.7381222706063638\n",
      "\tClass: 2 → error: 0.7428325668778795\n",
      "\tClass: 3 → error: 0.7374009371214665\n",
      "\tClass: 4 → error: 0.7421797228414575\n",
      "Iteration: 1500\n",
      "\tClass: 0 → error: 0.711137885919781\n",
      "\tClass: 1 → error: 0.7190988974394433\n",
      "\tClass: 2 → error: 0.7117905768750896\n",
      "\tClass: 3 → error: 0.7192954608235651\n",
      "\tClass: 4 → error: 0.713067871165519\n",
      "Iteration: 1600\n",
      "\tClass: 0 → error: 0.6885073264157487\n",
      "\tClass: 1 → error: 0.6952871239876491\n",
      "\tClass: 2 → error: 0.6887171257439753\n",
      "\tClass: 3 → error: 0.6954123451356695\n",
      "\tClass: 4 → error: 0.6877787954878734\n",
      "Iteration: 1700\n",
      "\tClass: 0 → error: 0.6648008288943835\n",
      "\tClass: 1 → error: 0.6798148444008543\n",
      "\tClass: 2 → error: 0.6645727462221529\n",
      "\tClass: 3 → error: 0.6794250913709894\n",
      "\tClass: 4 → error: 0.6646387248561145\n",
      "Iteration: 1800\n",
      "\tClass: 0 → error: 0.6432225968063836\n",
      "\tClass: 1 → error: 0.6464236405298873\n",
      "\tClass: 2 → error: 0.6425755771801471\n",
      "\tClass: 3 → error: 0.6440913257469492\n",
      "\tClass: 4 → error: 0.6418479609952015\n",
      "Iteration: 1900\n",
      "\tClass: 0 → error: 0.6203495323883861\n",
      "\tClass: 1 → error: 0.6327675323583604\n",
      "\tClass: 2 → error: 0.620589937129653\n",
      "\tClass: 3 → error: 0.6329963321039764\n",
      "\tClass: 4 → error: 0.6208635069142894\n",
      "Iteration: 1999\n",
      "\tClass: 0 → error: 0.6089617449049637\n",
      "\tClass: 1 → error: 0.5982969103467438\n",
      "\tClass: 2 → error: 0.6084509237107226\n",
      "\tClass: 3 → error: 0.5987872504442641\n",
      "\tClass: 4 → error: 0.6081309991395616\n"
     ]
    }
   ],
   "source": [
    "svm = SVM(X_train,y_train_enc, classes_no=5)\n",
    "training_result = svm.fit(\n",
    "    num_iterations=2000,\n",
    "    lr=0.00029,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the given data → 71.42857142857143%\n"
     ]
    }
   ],
   "source": [
    "X_test_flat, y_test_enc_multi = prepare_data(X_test, y_test_enc)\n",
    "preds = svm.predict(X_test)\n",
    "size = np.size(preds - y_test_enc)\n",
    "acc = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i]== y_test_enc[i]:\n",
    "        acc += 1\n",
    "\n",
    "print(\n",
    "    f\"Accuracy for the given data → {(acc/size)*100}%\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
