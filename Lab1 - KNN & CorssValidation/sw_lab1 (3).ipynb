{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confidential-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import numpy as np\n",
    "\n",
    "required = {\"scikit-image\"}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call(\n",
    "        [python, \"-m\", \"pip\", \"install\", *missing], stdout=subprocess.DEVNULL\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-genealogy",
   "metadata": {},
   "source": [
    "###### 1. Opis danych dla pierwszych 6 zajęć laboratoryjnych\n",
    "\n",
    "Dane są dostępne w postaci spakowanej w pliku <a href=\"http://fraktal.faculty.wmi.amu.edu.pl/symulowanie_wizualne/train_test_sw.zip\">train_test_sw.zip</a>. Po rozpakowaniu otrzymujmemy katalog <i>train_test_sw</i> zawierający:\n",
    "\n",
    "<ol>\n",
    "        <li>katalog <i>train_sw</i> - katalog z listą podkatalogów przechowujących obrazy treningowe (format 4-bajtowy rgba) podzielone na kategorie - nazwa katalogu odpowiada nazwie kategorii\n",
    "     <li>katalog <i>test_sw</i> - katalog z listą plików zawierających obrazy testowe   \n",
    "     <li>plik <i>test_labels.json</i> - zawiera etykiety obrazów testowych  w formacie JSON - pojedyncza dana to słownik  \n",
    "         <p>\n",
    "             <code>\n",
    "                 {\n",
    "                    \"filename\": nazwa pliku,\n",
    "                    \"value\": nazwa_kategorii\n",
    "                 }\n",
    "            </code>\n",
    " </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-mattress",
   "metadata": {},
   "source": [
    "#### 2. Funkcja <code>load_train_data(input_dir, newSize=(64,64))</code>\n",
    "\n",
    "Funkcja ta wczytuje dane teningowe, przeskalowuje je do rozmiaru podanego w drugim parametrze (z interpolacją typu cv2.INTER_AREA), przeprowadza ich normalizację i zwraca słownik w formacie:\n",
    "\n",
    "<p>\n",
    "<code>\n",
    "{  \"data\" - lista (typ <code>list</code>) obrazów, gdzie pojedynczy obraz jest tablicą <code>numpy.array</code> zapisaną wierszowo blokami rgb\n",
    "   \"categories_name\" - lista nazw kategorii klasyfikacyjnych, gdzie pojedyncza nazwa kategorii jest typu <code>str</code>\n",
    "   \"categories_count\" - lista ilości przykładów z pozszczególnych kategorii w danych treningowych \n",
    "   \"labels\" - lista etykiet wszystkich danych treningowych\n",
    " }\n",
    " </code>\n",
    " \n",
    " Parametry:\n",
    "    \n",
    " - <code>input_dir</code> przyjmuje wartość  ścieżki katalogu 'train_sw'\n",
    " - <code>newSize</code> przyjmuje wartość  krotki określającej rozmiar przeskalowanych obrazów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indirect-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(input_dir, newSize=(64, 64)):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from skimage.io import imread\n",
    "    import cv2 as cv\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    from shutil import copyfile, rmtree\n",
    "    import json\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import matplotlib\n",
    "\n",
    "    image_dir = Path(input_dir)\n",
    "    categories_name = []\n",
    "    for file in os.listdir(image_dir):\n",
    "        d = os.path.join(image_dir, file)\n",
    "        if os.path.isdir(d):\n",
    "            categories_name.append(file)\n",
    "\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "\n",
    "    train_img = []\n",
    "    categories_count = []\n",
    "    labels = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        count = 0\n",
    "        for obj in direc.iterdir():\n",
    "            if (\n",
    "                os.path.isfile(obj)\n",
    "                and os.path.basename(os.path.normpath(obj)) != \"desktop.ini\"\n",
    "            ):\n",
    "                labels.append(os.path.basename(os.path.normpath(direc)))\n",
    "                count += 1\n",
    "                img = imread(obj)  # zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "                img = cv.resize(\n",
    "                    img, newSize, interpolation=cv.INTER_AREA\n",
    "                )  # zwraca ndarray\n",
    "                if img[0][0].size==3:\n",
    "                    img =  np.dstack((img,np.ones((64,64,1))))\n",
    "                img = img / 255  # normalizacja\n",
    "                train_img.append(img)\n",
    "        categories_count.append(count)\n",
    "    X = {}\n",
    "    X[\"values\"] = np.array(train_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"] = labels\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "precise-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beech', 'Gardenia', 'Lemon', 'Mean', 'Tomato']\n",
      "[406, 206, 412, 412, 412]\n",
      "['Beech', 'Beech', 'Beech']\n",
      "[0.3843137254901961, 0.08627450980392157, 0.11764705882352941, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = load_train_data(\"./train_test_sw/train_sw\")\n",
    "print(data[\"categories_name\"])\n",
    "print(data[\"categories_count\"])\n",
    "print([data[\"labels\"][50], data[\"labels\"][200], data[\"labels\"][300]])\n",
    "print(list(data[\"values\"][100][1][10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-talent",
   "metadata": {},
   "source": [
    "#### 3. Funkcja <code>load_test_data(input_dir, newSize=(64,64))</code>\n",
    "\n",
    "Funkcja ta wczytuje dane testowe, przeskalowuje je do rozmiaru podanego w drugim parametrze (z\n",
    "interpolacją typu cv2.INTER_AREA), przeprowadza ich normalizację i zwraca słownik w formacie:\n",
    "\n",
    "<p>\n",
    "    \n",
    "<code>\n",
    "{  \"data\" - lista (typ <code>list</code>) obrazów, gdzie pojedynczy obraz jest tablicą <code>numpy.array</code> zapisaną wierszowo blokami rgb\n",
    "   \"categories_name\" - lista nazw kategorii klasyfikacyjnych, gdzie pojedyncza nazwa kategorii jest typu <code>str</code>\n",
    "   \"categories_count\" - lista ilości przykładów z pozszczególnych kategorii w danych testowych \n",
    "   \"labels\" - lista etykiet wszystkich danych testowych\n",
    " }\n",
    " </code>\n",
    " \n",
    " Parametry:\n",
    "    \n",
    " - <code>input_dir</code> przyjmuje wartość  ścieżki katalogu 'test_sw'\n",
    " - <code>newSize</code> przyjmuje wartość  krotki określającej rozmiar przeskalowanych obrazów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "difficult-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(input_dir, newSize=(64, 64)):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from skimage.io import imread\n",
    "    import cv2 as cv\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    from shutil import copyfile, rmtree\n",
    "    import json\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import matplotlib\n",
    "\n",
    "    image_path = Path(input_dir)\n",
    "\n",
    "    labels_path = image_path.parents[0] / \"test_labels.json\"\n",
    "\n",
    "    # with labels_path.open(\"r\", encoding =\"utf-8\") as f:\n",
    "    jsonString = labels_path.read_text()\n",
    "    objects = json.loads(jsonString)\n",
    "\n",
    "    # print(objects)\n",
    "\n",
    "    categories_name = []\n",
    "    categories_count = []\n",
    "    count = 0\n",
    "    c = objects[0][\"value\"]\n",
    "    for e in objects:\n",
    "        if e[\"value\"] != c:\n",
    "            # print(count)\n",
    "            # print(c)\n",
    "            categories_count.append(count)\n",
    "            c = e[\"value\"]\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "        if not e[\"value\"] in categories_name:\n",
    "            categories_name.append(e[\"value\"])\n",
    "\n",
    "    categories_count.append(count)\n",
    "\n",
    "    test_img = []\n",
    "\n",
    "    labels = []\n",
    "    for e in objects:\n",
    "        p = image_path / e[\"filename\"]\n",
    "        img = imread(p)  # zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "        img = cv.resize(img, newSize, interpolation=cv.INTER_AREA)  # zwraca ndarray\n",
    "        img = img / 255  # normalizacja\n",
    "        test_img.append(img)\n",
    "        labels.append(e[\"value\"])\n",
    "\n",
    "    X = {}\n",
    "    X[\"values\"] = np.array(test_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"] = labels\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "smaller-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beech', 'Gardenia', 'Lemon', 'Mean', 'Tomato']\n",
      "[51, 52, 52, 52, 52]\n",
      "['Beech', 'Beech', 'Beech']\n",
      "[0.058823529411764705, 0.00784313725490196, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = load_test_data(\"./train_test_sw/test_sw\")\n",
    "print(data[\"categories_name\"])\n",
    "print(data[\"categories_count\"])\n",
    "print([data[\"labels\"][10], data[\"labels\"][20], data[\"labels\"][30]])\n",
    "print(list(data[\"values\"][10][1][10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d233bf",
   "metadata": {},
   "source": [
    "## Skład zespołu:\n",
    "- Jakub Eichner 478874\n",
    "- Mateusz Ogrodowczyk 478841\n",
    "- Julian Zabłoński 478831\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-purchase",
   "metadata": {},
   "source": [
    "#### 4. Zadanie 1 (4pkt):\n",
    "\n",
    "Napisz kod klasy <code>KNearestNeighbor</code> implementującej klasyfikator <i>knn</i>. Należy zimplementować następujące metody:\n",
    "\n",
    "- <code>konstruktor</code> pobierający listę obrazów treningowych (zgodną zw składową 'values' wczytanego słownika) oraz listę ich etykiet\n",
    "- metoda <code>l_p_metric(image1, image2, p):</code> zwracająca wartość odległości pomiędzy dwoma obrazami, mierzoną normą typu <i>l_p</i> - parametr <code>p</code> określa 'potęgę' normy\n",
    "- metoda <code>predict(test_images, k,p):</code> zwracająca listę prognozowanych etykiet dla obrazów testowych (parametr <code>test_images</code>). Paramter drugi określa liczbę przeszukiwanych sąsiadów, natomiast paramter trzeci określa potęgę wybranej metryki.\n",
    "- metoda <code>accuracy(test_images, k,p)</code> zwracająca dokładność klasyfikatora na zbiorze testowym. Parametr drugi i trzeci są jak w metodzie <code>predict()</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "great-earthquake",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-50c8d2866e4d875e",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNearestNeighbor(object):\n",
    "    def __init__(self, values, labels) -> None:\n",
    "        self.values = values\n",
    "        self.labels = labels\n",
    "        #self.imgs_no = len(self.values)\n",
    "\n",
    "    def l_p_metric(self, image1, image2, p, i):\n",
    "        # if (i[1] + 1) % 500 == 0 or i[1] + 1 == self.imgs_no:\n",
    "#         if i[1] + 1 == self.imgs_no and (\n",
    "#             (i[0] + 1) % 25 == 0 or i[0] == self.currently_predicted_no\n",
    "#         ):\n",
    "#             print(\n",
    "#                 f\"Calculating distance between the {i[0]+1}/{self.currently_predicted_no} image for the {i[1]+1}/{self.imgs_no} value\"\n",
    "#             )\n",
    "        return pow(np.sum(pow(abs(image1 - image2) + 1e-16, p)), 1 / p)\n",
    "\n",
    "    def predict(self, test_images, K, P):\n",
    "        self.currently_predicted_no = len(test_images)\n",
    "        diffs = [\n",
    "            [\n",
    "                (\n",
    "                    learned_data[1],\n",
    "                    self.l_p_metric(test_img, learned_data[0], P, (img_no, i)),\n",
    "                )\n",
    "                for i, learned_data in enumerate(zip(self.values, self.labels))\n",
    "            ]\n",
    "            for img_no, test_img in enumerate(test_images)\n",
    "        ]\n",
    "        # we create a list of the K nearest neighbours for each test imag\n",
    "        neighbours = [sorted(distances, key=lambda x: x[1])[:K] for distances in diffs]\n",
    "        neigh_keys = [(x[0] for x in neighs_list) for neighs_list in neighbours]\n",
    "        result_neighbours = [\n",
    "            Counter(neighs).most_common(1)[0][0] for neighs in neigh_keys\n",
    "        ]\n",
    "        return np.array(result_neighbours)\n",
    "\n",
    "    def accuracy(self, test_labels, pred_labels):\n",
    "        comparison_results = [\n",
    "            label == pred for label, pred in zip(test_labels, pred_labels)\n",
    "        ]\n",
    "        return sum(comparison_results) / len(comparison_results)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Values {self.values}\\nLabels: {self.labels}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "searching-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_train = load_train_data(\"./train_test_sw/train_sw\", newSize=(64, 64))\n",
    "X_train = data_train[\"values\"]\n",
    "y_train = data_train[\"labels\"]\n",
    "\n",
    "\n",
    "data_test = load_test_data(\"./train_test_sw/test_sw\", newSize=(64, 64))\n",
    "X_test = data_test[\"values\"]\n",
    "y_test = data_test[\"labels\"]\n",
    "\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y_train_enc = class_le.fit_transform(y_train)\n",
    "y_test_enc = class_le.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d34a8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 1 neighbour and P=1 → 0.583011583011583\n",
      "Accuracy for 1 neighbour and P=2 → 0.5521235521235521\n",
      "Accuracy for 5 neighbours and P=1 → 0.555984555984556\n",
      "Accuracy for 5 neighbour and P=2 → 0.5444015444015444\n",
      "Accuracy for 10 neighbours and P=1 → 0.5019305019305019\n",
      "Accuracy for 10 neighbours and P=2 → 0.5019305019305019\n"
     ]
    }
   ],
   "source": [
    "Knn = KNearestNeighbor(X_train, y_train_enc)\n",
    "\n",
    "pred = Knn.predict(test_images=X_test, K=1, P=1)\n",
    "print(f'Accuracy for 1 neighbour and P=1 → {Knn.accuracy(y_test_enc, pred)}')\n",
    "\n",
    "pred = Knn.predict(X_test, K=1, P=2)\n",
    "print(f'Accuracy for 1 neighbour and P=2 → {Knn.accuracy(y_test_enc, pred)}')\n",
    "\n",
    "pred = Knn.predict(X_test, K=5, P=1)\n",
    "print(f'Accuracy for 5 neighbours and P=1 → {Knn.accuracy(y_test_enc, pred)}')\n",
    "\n",
    "pred = Knn.predict(X_test, K=5, P=2)\n",
    "print(f'Accuracy for 5 neighbour and P=2 → {Knn.accuracy(y_test_enc, pred)}')\n",
    "\n",
    "pred = Knn.predict(X_test, K=10, P=1)\n",
    "print(f'Accuracy for 10 neighbours and P=1 → {Knn.accuracy(y_test_enc, pred)}')\n",
    "\n",
    "pred = Knn.predict(X_test, K=10, P=2)\n",
    "print(f'Accuracy for 10 neighbours and P=2 → {Knn.accuracy(y_test_enc, pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-replacement",
   "metadata": {},
   "source": [
    "#### 5. Zadanie 2 (2pkt):\n",
    "\n",
    "Napisz kod funkcji <code>crossValidation(X,y, n = 10, k=1,p=1 ):</code> obliczającą algorytm <code>knn </code> z n-krotną walidacją krzyżową.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "entire-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "def crossValidation(X, y, n=10, k=1, p=1):\n",
    "    \"\"\"\n",
    "    :param X: train data\n",
    "    :param y: encoded labels of train data\n",
    "    :param n: value for n-fold cross validation\n",
    "    :param k: k value  for knn\n",
    "    :param p: p value for l_p metric\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # BEGIN SOLUTION \n",
    "    s_x = np.split(X, n)\n",
    "    s_y = np.split(y, n)\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    for i in range(n):\n",
    "        test_x, test_y = s_x[i], s_y[i]\n",
    "        train_x, train_y = chain(*s_x[:i], *s_x[i+1:]), chain(*s_y[:i], *s_y[i+1:])\n",
    "        Knn  = KNearestNeighbor(train_x, train_y)\n",
    "        pred = Knn.predict(test_x,k,p)\n",
    "        accs.append(Knn.accuracy(test_y,pred))\n",
    "\n",
    "    #print(accs)\n",
    "    print(f'Avarage accuracy => {np.mean(accs)}')\n",
    "    return accs\n",
    "\n",
    "    #END SOLUTION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3de3d84b-b8fb-418f-9491-df333e387ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avarage accuracy => 0.479978354978355\n"
     ]
    }
   ],
   "source": [
    "res = crossValidation(X_train, y_train_enc, n=len(X_train), k=5, p=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bb37f",
   "metadata": {},
   "source": [
    "#### 6. Zadanie 3 (4pkt):\n",
    "\n",
    "Napisz kod klasy <code>LogisticRegression</code> implementującej klasyfikator <i>wieloklasowej regresji logistycznej</i> z funkcją <code>softmax()</code> (ze standardowymi nazwami dwóch kluczowych funkcji: <i>fit()</i>, <i>predict()</i>). Zastosuj ten kod do pobranych danych (zbiór walidacyjny losujemy ze zbioru treningowego) - oblicz następujące charakterystyki modelu dla danych walidacyjnych oraz treningowych: dokładność (accuracy), precyzję (precision), czułość(recall) oraz F1 - dla poszczególnych klas oraz globalnie (zob. np. <a href=\"https://medium.com/synthesio-engineering/precision-accuracy-and-f1-score-for-multi-label-classification-34ac6bdfb404\">tu</a>).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e433be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, data_shape, classes_no) -> None:\n",
    "        self.w = np.zeros(shape=(classes_no, data_shape[0], 1))\n",
    "        self.b = np.zeros(shape=(classes_no, 1))\n",
    "        print(f\"self.w.shape = {self.w.shape}\\nself.b.shape = {self.b.shape}\")\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z)) - 0.0000001\n",
    "\n",
    "    def propagate(self, w, b, X, Y):\n",
    "        data_len = X.shape[1]\n",
    "        \n",
    "        A = self.sigmoid((np.dot(w.T, X) + b))\n",
    "        \n",
    "        cost = np.sum(((-np.log(A)) * Y + (-np.log(1 - A)) * (1 - Y))) / data_len\n",
    "        \n",
    "        cost = np.squeeze(cost)\n",
    "        \n",
    "        dw = (np.dot(X, (A - Y).T)) / data_len\n",
    "        \n",
    "        db = (np.sum(A - Y)) / data_len\n",
    "\n",
    "        grads = {\"dw\": dw, \"db\": db}\n",
    "        return grads, cost\n",
    "\n",
    "    def train(self, X, Y, num_iterations, lr, verbose=False):\n",
    "        error_vals = [[] for i in range(self.w.shape[0])]\n",
    "        for i in range(num_iterations):\n",
    "            if (i + 1) % 100 == 1 or i == num_iterations - 1:\n",
    "                print(\"Iteration:\", i)\n",
    "            for ent_class in range(self.w.shape[0]):\n",
    "                \n",
    "                grads, cost = self.propagate(\n",
    "                    self.w[ent_class], self.b[ent_class], X, Y[ent_class]\n",
    "                )\n",
    "                # print(f\"\\t{i}before w update\")\n",
    "                self.w[ent_class] -= lr * grads[\"dw\"]\n",
    "                # print(\"\\tbefore b update\")\n",
    "                self.b[ent_class] -= lr * grads[\"db\"]\n",
    "                if (i + 1) % 100 == 1 or i == num_iterations - 1:\n",
    "                    error_vals[ent_class].append(cost)\n",
    "                    if verbose:\n",
    "                        print(f\"\\tClass: {ent_class} → error: {cost}\")\n",
    "        return {\n",
    "            \"parameters\": {\"w\": self.w, \"b\": self.b},\n",
    "            \"gradients\": grads,\n",
    "            \"error_values\": error_vals,\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        data_len = X.shape[1]\n",
    "        \n",
    "        A = np.array(\n",
    "            [\n",
    "                self.sigmoid(np.dot(current_w.reshape(X.shape[0], -1).T, X) + current_b)\n",
    "                for current_w, current_b in zip(self.w, self.b)\n",
    "            ]\n",
    "        )\n",
    "        Y_pred = [(class_preds > 0.5) * 1.0 for class_preds in A]  # A * 5.0\n",
    "        return Y_pred\n",
    "\n",
    "    def validate(self, test_data, true_labels):\n",
    "        preds = self.predict(test_data)\n",
    "        return f\"Accuracy for the given data → {100 - np.mean(np.abs(preds - true_labels))*100}\"\n",
    "\n",
    "\n",
    "def prepare_data(x_data, y_data):\n",
    "    x = x_data.reshape(x_data.shape[0], -1).T\n",
    "    y = np.array([[int(x == i) for i in y_data] for x in range(len(set(y_data)))])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca163ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.w.shape = (5, 16384, 1)\n",
      "self.b.shape = (5, 1)\n",
      "Iteration: 0\n",
      "\tClass: 0 → error: 0.693147068438753\n",
      "\tClass: 1 → error: 0.6931470251487096\n",
      "\tClass: 2 → error: 0.6931470697374542\n",
      "\tClass: 3 → error: 0.6931470697374542\n",
      "\tClass: 4 → error: 0.6931470697374542\n",
      "Iteration: 100\n",
      "\tClass: 0 → error: 0.5157444236726193\n",
      "\tClass: 1 → error: 0.28246828140335944\n",
      "\tClass: 2 → error: 0.5252240196030604\n",
      "\tClass: 3 → error: 0.5189321738772411\n",
      "\tClass: 4 → error: 0.5222111819329334\n",
      "Iteration: 200\n",
      "\tClass: 0 → error: 0.5059211686007784\n",
      "\tClass: 1 → error: 0.2777127183186381\n",
      "\tClass: 2 → error: 0.5186898143236112\n",
      "\tClass: 3 → error: 0.5142815434224718\n",
      "\tClass: 4 → error: 0.5181261463700836\n",
      "Iteration: 300\n",
      "\tClass: 0 → error: 0.4972898240996385\n",
      "\tClass: 1 → error: 0.2749221120401529\n",
      "\tClass: 2 → error: 0.5128841297366997\n",
      "\tClass: 3 → error: 0.5102354194969786\n",
      "\tClass: 4 → error: 0.5146483236050161\n",
      "Iteration: 400\n",
      "\tClass: 0 → error: 0.4895375243174669\n",
      "\tClass: 1 → error: 0.2729949006339826\n",
      "\tClass: 2 → error: 0.5075623954318662\n",
      "\tClass: 3 → error: 0.5065360610929932\n",
      "\tClass: 4 → error: 0.5114799062318632\n",
      "Iteration: 500\n",
      "\tClass: 0 → error: 0.4824537502902446\n",
      "\tClass: 1 → error: 0.2714684491732171\n",
      "\tClass: 2 → error: 0.5025900179422066\n",
      "\tClass: 3 → error: 0.503089574468444\n",
      "\tClass: 4 → error: 0.5085399952593905\n",
      "Iteration: 600\n",
      "\tClass: 0 → error: 0.4758942497977346\n",
      "\tClass: 1 → error: 0.27014612211458305\n",
      "\tClass: 2 → error: 0.497888269238134\n",
      "\tClass: 3 → error: 0.49983703449048494\n",
      "\tClass: 4 → error: 0.505777880091543\n",
      "Iteration: 700\n",
      "\tClass: 0 → error: 0.469758007543232\n",
      "\tClass: 1 → error: 0.2689408989724881\n",
      "\tClass: 2 → error: 0.4934079183608687\n",
      "\tClass: 3 → error: 0.4967380164939549\n",
      "\tClass: 4 → error: 0.503156900597965\n",
      "Iteration: 800\n",
      "\tClass: 0 → error: 0.4639726002031416\n",
      "\tClass: 1 → error: 0.26781179514100256\n",
      "\tClass: 2 → error: 0.48911611510038416\n",
      "\tClass: 3 → error: 0.4937640227025572\n",
      "\tClass: 4 → error: 0.5006500432993702\n",
      "Iteration: 900\n",
      "\tClass: 0 → error: 0.45848484136235435\n",
      "\tClass: 1 → error: 0.2667379327673605\n",
      "\tClass: 2 → error: 0.48498960329782626\n",
      "\tClass: 3 → error: 0.4908945388919331\n",
      "\tClass: 4 → error: 0.4982372274708627\n",
      "Iteration: 1000\n",
      "\tClass: 0 → error: 0.45325473624368806\n",
      "\tClass: 1 → error: 0.2657076728632699\n",
      "\tClass: 2 → error: 0.4810110428488202\n",
      "\tClass: 3 → error: 0.4881145026087994\n",
      "\tClass: 4 → error: 0.495903395536351\n",
      "Iteration: 1100\n",
      "\tClass: 0 → error: 0.44825151272646746\n",
      "\tClass: 1 → error: 0.26471388463333134\n",
      "\tClass: 2 → error: 0.47716692089735296\n",
      "\tClass: 3 → error: 0.4854126367903653\n",
      "\tClass: 4 → error: 0.49363715056812846\n",
      "Iteration: 1200\n",
      "\tClass: 0 → error: 0.44345096872523987\n",
      "\tClass: 1 → error: 0.26375179579813246\n",
      "\tClass: 2 → error: 0.47344631170725493\n",
      "\tClass: 3 → error: 0.48278033197870496\n",
      "\tClass: 4 → error: 0.4914297791059481\n",
      "Iteration: 1300\n",
      "\tClass: 0 → error: 0.43883366712703586\n",
      "\tClass: 1 → error: 0.26281796721665107\n",
      "\tClass: 2 → error: 0.46984010979163576\n",
      "\tClass: 3 → error: 0.48021088437203446\n",
      "\tClass: 4 → error: 0.48927454670255266\n",
      "Iteration: 1400\n",
      "\tClass: 0 → error: 0.43438368621453327\n",
      "\tClass: 1 → error: 0.2619097753985791\n",
      "\tClass: 2 → error: 0.46634053795661057\n",
      "\tClass: 3 → error: 0.4776989692822004\n",
      "\tClass: 4 → error: 0.48716618737573175\n",
      "Iteration: 1500\n",
      "\tClass: 0 → error: 0.4300877408343342\n",
      "\tClass: 1 → error: 0.26102513364649993\n",
      "\tClass: 2 → error: 0.46294082113518303\n",
      "\tClass: 3 → error: 0.47524027295715676\n",
      "\tClass: 4 → error: 0.4851005316265864\n",
      "Iteration: 1600\n",
      "\tClass: 0 → error: 0.42593455535290436\n",
      "\tClass: 1 → error: 0.2601623305725691\n",
      "\tClass: 2 → error: 0.4596349636167564\n",
      "\tClass: 3 → error: 0.47283123244262687\n",
      "\tClass: 4 → error: 0.48307423399609783\n",
      "Iteration: 1700\n",
      "\tClass: 0 → error: 0.4219144103530197\n",
      "\tClass: 1 → error: 0.25931992963246514\n",
      "\tClass: 2 → error: 0.4564175927024047\n",
      "\tClass: 3 → error: 0.4704688500179097\n",
      "\tClass: 4 → error: 0.48108457249606407\n",
      "Iteration: 1800\n",
      "\tClass: 0 → error: 0.41801881092323234\n",
      "\tClass: 1 → error: 0.2584967025033187\n",
      "\tClass: 2 → error: 0.4532838461611168\n",
      "\tClass: 3 → error: 0.46815055961818475\n",
      "\tClass: 4 → error: 0.47912930020334776\n",
      "Iteration: 1900\n",
      "\tClass: 0 → error: 0.4142402411045218\n",
      "\tClass: 1 → error: 0.25769158258932545\n",
      "\tClass: 2 → error: 0.4502292892380336\n",
      "\tClass: 3 → error: 0.4658741298102377\n",
      "\tClass: 4 → error: 0.47720653489874754\n",
      "Iteration: 1999\n",
      "\tClass: 0 → error: 0.4106081370325132\n",
      "\tClass: 1 → error: 0.2569114286727443\n",
      "\tClass: 2 → error: 0.44727928710907194\n",
      "\tClass: 3 → error: 0.463659766492354\n",
      "\tClass: 4 → error: 0.47533344686788764\n"
     ]
    }
   ],
   "source": [
    "X_train_flat, y_train_enc_multi = prepare_data(X_train, y_train_enc)\n",
    "\n",
    "#Logistic Regression training\n",
    "log_reg = LogisticRegression(X_train_flat.shape, 5)\n",
    "training_result = log_reg.train(\n",
    "    X_train_flat, y_train_enc_multi, num_iterations=2000, lr=0.0029, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ea55fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the given data → 79.58301158301158%\n",
      "Precision for the given data → 0.7958301158301159\n",
      "Recall for the given data → 0.9930622470610908\n",
      "F1 score for the given data → 0.8835733882030178\n"
     ]
    }
   ],
   "source": [
    "X_test_flat, y_test_enc_multi = prepare_data(X_test, y_test_enc)\n",
    "\n",
    "preds = log_reg.predict(X_test_flat)\n",
    "size = np.size(preds - y_test_enc_multi)\n",
    "fp = np.sum(np.abs(preds - y_test_enc_multi))\n",
    "tp = size - fp\n",
    "fn = np.count_nonzero((preds - y_test_enc_multi)>0)\n",
    "\n",
    "print(f'Accuracy for the given data → {100 - np.mean(np.abs(preds - y_test_enc_multi))*100}%')\n",
    "print(f'Precision for the given data → { tp/(tp+fp) }')\n",
    "print(f'Recall for the given data → { tp/(tp+fn) }')\n",
    "print(f'F1 score for the given data → { 2*tp / (2*tp + fp + fn) }')\n",
    "\n",
    "\n",
    "\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8326ba",
   "metadata": {},
   "source": [
    "#### 7. Zadanie 4 (1pkt):\n",
    "\n",
    "Oblicz ile danych z poszczególnych klas znajduje się po dodatniej/ujemnej stronie hiperpłaszczyzny klasyfikacyjnej dla danej klasy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09f0a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beech → 44.0 / 51\n",
      "Gardenia → 52.0 / 52\n",
      "Lemon → 52.0 / 52\n",
      "Mean → 52.0 / 52\n",
      "Tomato → 54.0 / 52\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION (zad. 4)\n",
    "\n",
    "classes_ids = {\n",
    "    'Beech': 0,\n",
    "    'Gardenia': 1,\n",
    "    'Lemon': 2,\n",
    "    'Mean': 3,\n",
    "    'Tomato': 4\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in classes_ids.items():\n",
    "    print(f'{k} → {np.sum(np.abs(preds[v] - y_test_enc_multi[v]))} / {y_test.count(k)}')\n",
    "\n",
    "# END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cb483",
   "metadata": {},
   "source": [
    "#### 8. Dwa uzupełnienia\n",
    "\n",
    "W pliku [lab1_add](lab1_add.ipynb) znajdują się minimalne podstawy teoretyczne związane z konstrukcją funkcji kosztu oraz algorytmami optymalizacji.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
